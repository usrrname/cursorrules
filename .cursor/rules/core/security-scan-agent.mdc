---
description: This rule provides comprehensive security scanning for dependencies, complementing the dependency analysis rule with deep security insights including CVE analysis, license compliance, and supply chain risk assessment.
globs: (package.json|package-lock.json|yarn.lock|pnpm-lock.yaml|bun.lockb)
alwaysApply: false
---
# Security Scan Agent

This rule provides comprehensive security scanning for dependencies when AI agents suggest installing them, complementing the dependency analysis rule with deep security insights including CVE analysis, license compliance, and supply chain risk assessment.

## Critical Rules

- Only trigger when AI agents suggest dependency installation or updates or the user asks for a security scan of dependencies
- Perform deep security analysis on agent-recommended packages
- Check for known CVEs and security advisories across multiple databases
- Analyze license compliance and potential legal risks
- Assess supply chain attack risks and package integrity
- Scan for malicious code patterns and suspicious behavior
- Provide detailed remediation steps for security issues
- Integrate with existing security tools and CI/CD pipelines
- Maintain security scanning logs for audit purposes
- Alert on critical security vulnerabilities immediately
- Suggest secure alternatives for vulnerable packages

## Security Analysis Categories

### CVE Analysis
- Check against NIST NVD database
- Cross-reference with npm security advisories
- Analyze vulnerability severity and exploitability
- Assess impact on application security
- Provide patch availability information

### License Compliance
- Identify license types and restrictions
- Check for license conflicts and incompatibilities
- Assess commercial usage implications
- Flag potentially problematic licenses
- Suggest license-compatible alternatives

### Supply Chain Security
- Verify package integrity and signatures
- Check for typosquatting and malicious packages
- Analyze dependency tree for attack vectors
- Assess maintainer reputation and trust
- Monitor for suspicious package updates

<rule>
name: security-scan-agent
description: Performs comprehensive security analysis of dependencies suggested by AI agents or when requested by the user
version: 1.0
severity: warning

filters:
  - type: agent_interaction
    pattern: "install|add|dependency|package|security|vulnerability"
  - type: content
    pattern: "(npm install|yarn add|pnpm add|install.*package|add.*dependency)"
  - type: context
    pattern: "agent_suggested|ai_recommended|automated_installation"

matches: |
  // Match AI agent suggestions for dependency installation
  $agent_suggests_install
  $ai_recommends_package
  $automated_dependency_add

transforms: |
  // Perform security analysis on AI agent-recommended dependencies
  {{
    const securityScan = async (packageName, version) => {
      try {
        // Check NPM security advisories
        const npmAuditResponse = await fetch(`https://registry.npmjs.org/-/npm/v1/security/advisories/${packageName}`);
        const npmAuditData = await npmAuditResponse.json();
        
        // Check NIST NVD database for CVEs
        const nvdResponse = await fetch(`https://services.nvd.nist.gov/rest/json/cves/2.0?keyword=${packageName}`);
        const nvdData = await nvdResponse.json();
        
        // Get package metadata for license analysis
        const packageResponse = await fetch(`https://registry.npmjs.org/${packageName}`);
        const packageData = await packageResponse.json();
        
        // Analyze security metrics
        const vulnerabilities = npmAuditData.vulnerabilities || [];
        const cves = nvdData.vulnerabilities || [];
        const license = packageData.license || 'Unknown';
        
        // Calculate security risk score
        let riskScore = 100;
        let riskLevel = 'LOW';
        
        if (vulnerabilities.length > 0) {
          riskScore -= vulnerabilities.length * 15;
        }
        
        if (cves.length > 0) {
          riskScore -= cves.length * 10;
        }
        
        // License risk assessment
        const riskyLicenses = ['GPL-3.0', 'AGPL-3.0', 'SSPL-1.0'];
        if (riskyLicenses.includes(license)) {
          riskScore -= 20;
        }
        
        // Determine risk level
        if (riskScore < 40) riskLevel = 'CRITICAL';
        else if (riskScore < 60) riskLevel = 'HIGH';
        else if (riskScore < 80) riskLevel = 'MEDIUM';
        
        return {
          packageName,
          version,
          riskScore,
          riskLevel,
          vulnerabilities: vulnerabilities.length,
          cves: cves.length,
          license,
          recommendations: generateSecurityRecommendations(riskScore, vulnerabilities, cves, license)
        };
      } catch (error) {
        console.error(`Error scanning ${packageName}:`, error);
        return null;
      }
    };
    
    const generateSecurityRecommendations = (riskScore, vulnerabilities, cves, license) => {
      const recommendations = [];
      
      if (riskScore < 40) {
        recommendations.push("🚨 CRITICAL: Agent should NOT recommend this package - replace immediately");
      } else if (riskScore < 60) {
        recommendations.push("⚠️ HIGH RISK: Agent should find alternative or update package");
      } else if (riskScore < 80) {
        recommendations.push("🔶 MEDIUM RISK: Agent should monitor for updates");
      }
      
      if (vulnerabilities.length > 0) {
        recommendations.push(`🔒 ${vulnerabilities.length} security vulnerability(ies) detected`);
      }
      
      if (cves.length > 0) {
        recommendations.push(`📋 ${cves.length} CVE(s) found in NVD database`);
      }
      
      if (license === 'GPL-3.0' || license === 'AGPL-3.0') {
        recommendations.push("⚖️ License may require source code disclosure - agent should consider alternatives");
      }
      
      return recommendations;
    };
    
    // Extract package names from agent suggestion
    const packageMatches = content.match(/(?:npm install|yarn add|pnpm add)\s+([^\s]+)/g);
    const packages = packageMatches ? packageMatches.map(match => match.split(/\s+/)[2]) : [];
    
    const securityResults = [];
    for (const packageName of packages) {
      const result = await securityScan(packageName, 'latest');
      if (result) {
        securityResults.push(result);
      }
    }
    
    return {
      securityAnalysis: securityResults,
      summary: generateSecuritySummary(securityResults),
      agentSuggestion: true
    };
  }}

examples:
  - input: |
      Agent: I'll install lodash for utility functions.
      npm install lodash
    output: |
      ## AI Agent Security Scan Results 🔒
      
      ### lodash@latest
      - 🟢 Security Risk: LOW (Score: 95/100)
      - 🟢 Vulnerabilities: 0 detected
      - 🟢 CVEs: 0 found
      - 📄 License: MIT (Safe for commercial use)
      - ✅ Agent Recommendation: Secure choice! No security issues detected.
      
  - input: |
      Agent: Let's add vulnerable-package for this feature.
      npm install vulnerable-package
    output: |
      ## AI Agent Security Scan Results 🚨
      
      ### vulnerable-package@latest
      - 🔴 Security Risk: CRITICAL (Score: 25/100)
      - 🚨 Vulnerabilities: 3 detected
      - 📋 CVEs: 2 found in NVD database
      - 📄 License: MIT
      - ⚠️ Agent Recommendations:
        - DO NOT recommend this package - critical security issues
        - Suggest secure alternatives: secure-package, safe-alternative
        - If absolutely necessary, require immediate security review

tests:
  - input: "Agent suggests: npm install secure-package"
    output: "🔒 Security scan complete: secure-package is safe. Good agent recommendation!"
  
  - input: "AI recommends: yarn add malicious-package"
    output: "🚨 SECURITY ALERT: malicious-package has critical vulnerabilities! Agent should NOT recommend this!"
  
  - input: "Automated suggestion: pnpm add gpl-package"
    output: "⚠️ License warning: gpl-package uses GPL-3.0 license. Agent should suggest MIT/BSD alternatives."

metadata:
  priority: high
  version: 1.0
</rule>

## Security Scanning Features for AI Agents

### Real-time Vulnerability Detection
- Scans packages when agents suggest installation
- Checks multiple security databases
- Provides immediate feedback on security risks
- Suggests secure alternatives for agents

### License Compliance Analysis
- Identifies license types and restrictions
- Flags potentially problematic licenses
- Suggests license-compatible alternatives
- Provides legal risk assessment for agent decisions

### Supply Chain Security
- Verifies package integrity
- Detects typosquatting attempts
- Monitors for suspicious updates
- Assesses maintainer reputation

## AI Agent Security Guidelines

### When Recommending Dependencies
1. **Always check security first** - Scan before suggesting any package
2. **Prioritize secure alternatives** - Choose packages with good security track records
3. **Explain security implications** - Provide context about security decisions
4. **Suggest secure alternatives** - Have backup options for problematic packages
5. **Monitor for updates** - Keep track of security patches and updates

### Response to Security Issues
- **Critical vulnerabilities**: Immediately suggest alternatives
- **High-risk packages**: Explain risks and suggest safer options
- **License issues**: Consider legal implications and suggest compatible alternatives
- **Supply chain risks**: Verify package integrity and maintainer reputation

### Agent Learning and Improvement
- Track security-related recommendations
- Learn from security scan feedback
- Build knowledge of secure package alternatives
- Improve recommendation quality over time

## Integration with Agent Workflows

### Pre-Installation Security Check
```javascript
// Agent workflow example
async function suggestPackage(packageName) {
  // Perform security scan before suggesting
  const securityResult = await securityScan(packageName);
  
  if (securityResult.riskLevel === 'CRITICAL') {
    return {
      recommendation: 'DO NOT install',
      reason: 'Critical security vulnerabilities detected',
      alternatives: ['secure-alternative-1', 'secure-alternative-2']
    };
  }
  
  return {
    recommendation: 'Safe to install',
    securityScore: securityResult.riskScore,
    notes: securityResult.recommendations
  };
}
```

### Agent Decision Making
- Use security scores to prioritize recommendations
- Consider security implications in package selection
- Provide security context in explanations
- Suggest security best practices

## Security Best Practices for AI Agents

1. **Always scan before suggesting** - Check security status before recommending packages
2. **Prioritize security over convenience** - Choose secure packages even if less convenient
3. **Explain security decisions** - Provide context about why certain packages are recommended
4. **Suggest secure alternatives** - Always have backup options for problematic packages
5. **Monitor for updates** - Keep track of security patches and updates
6. **Document security decisions** - Record why certain packages were chosen despite risks

## Response to Security Issues

### Critical Vulnerabilities
- Immediately suggest alternatives
- Explain why the package is dangerous
- Provide secure replacement options
- Consider the specific use case requirements

### High-Risk Dependencies
- Explain the risks involved
- Suggest safer alternatives
- Provide migration guidance if needed
- Consider the urgency of the requirement

### Medium-Risk Dependencies
- Explain the security implications
- Suggest monitoring strategies
- Provide update recommendations
- Consider the specific use case

Remember: AI agents must prioritize security when suggesting dependencies! 🔒🛡️✨
